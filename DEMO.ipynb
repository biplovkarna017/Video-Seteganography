{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21151,"status":"ok","timestamp":1684336498276,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"},"user_tz":-345},"id":"O7pj-G0MYzYA","outputId":"729f0bd5-5a1b-4ee1-aeec-df7f8c481db6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gradio\n","  Downloading gradio-3.31.0-py3-none-any.whl (17.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles (from gradio)\n","  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n","Collecting aiohttp (from gradio)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Collecting fastapi (from gradio)\n","  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio)\n","  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client>=0.2.4 (from gradio)\n","  Downloading gradio_client-0.2.5-py3-none-any.whl (288 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from gradio)\n","  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub>=0.13.0 (from gradio)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n","Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Collecting mdit-py-plugins<=0.3.3 (from gradio)\n","  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n","Collecting orjson (from gradio)\n","  Downloading orjson-3.8.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.7)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n","Collecting python-multipart (from gradio)\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n","Collecting semantic-version (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets>=10.0 (from gradio)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (2023.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n","Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio)\n","  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n","Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->gradio)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->gradio)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->gradio)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->gradio)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->gradio)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2022.12.7)\n","Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n","  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.15)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n","Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio)\n","  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=04085a7f2d28ac31b61333eb1cba811dbe4559658eddeec30c52164cfd438b26\n","  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, multidict, h11, frozenlist, async-timeout, aiofiles, yarl, uvicorn, starlette, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, aiosignal, httpx, fastapi, aiohttp, gradio-client, gradio\n","Successfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 fastapi-0.95.2 ffmpy-0.3.0 frozenlist-1.3.3 gradio-3.31.0 gradio-client-0.2.5 h11-0.14.0 httpcore-0.17.0 httpx-0.24.0 huggingface-hub-0.14.1 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 multidict-6.0.4 orjson-3.8.12 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3 yarl-1.9.2\n"]}],"source":["!pip install gradio"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45037,"status":"ok","timestamp":1684346602912,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"},"user_tz":-345},"id":"RmaZVpa7mlVn","outputId":"7c171ba2-a0d0-40b0-fb3c-ed2f7326736a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"MtSYEgVrmYjZ"},"source":["<h1>Steganography Model</h1>\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4869,"status":"ok","timestamp":1684336535839,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"},"user_tz":-345},"id":"PEv5cB1omxgR"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np \n","import pandas as pd\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import pywt \n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684336535840,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"},"user_tz":-345},"id":"4El2j2Munktv"},"outputs":[],"source":["\n","class PrepNetwork1(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=50,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=3,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv3 = nn.Conv2d(in_channels=3,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv4 = nn.Conv2d(in_channels=65,out_channels=50,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv5 = nn.Conv2d(in_channels=65,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv6 = nn.Conv2d(in_channels=65,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","    \n","    def forward(self,secret_image):\n","        output_1 = F.relu(self.conv1(secret_image))\n","        output_2 = F.relu(self.conv2(secret_image))\n","        output_3 = F.relu(self.conv3(secret_image))\n","        \n","        concatenated_image = torch.cat([output_1,output_2,output_3],dim=1)\n","        output_4 = F.relu(self.conv4(concatenated_image))\n","        output_5 = F.relu(self.conv5(concatenated_image))\n","        output_6 = F.relu(self.conv6(concatenated_image))\n","        \n","        final_concat_image = torch.cat([output_4,output_5,output_6],dim=1)\n","        return final_concat_image\n","\n","class HidingNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels=68,out_channels=50,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=68,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv3 = nn.Conv2d(in_channels=68,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv4 = nn.Conv2d(in_channels=65,out_channels=50,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv5 = nn.Conv2d(in_channels=65,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv6 = nn.Conv2d(in_channels=65,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv7 = nn.Conv2d(in_channels=65,out_channels=50,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv8 = nn.Conv2d(in_channels=65,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv9 = nn.Conv2d(in_channels=65,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv10 = nn.Conv2d(in_channels=65,out_channels=50,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv11 = nn.Conv2d(in_channels=65,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv12 = nn.Conv2d(in_channels=65,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv13 = nn.Conv2d(in_channels=65,out_channels=50,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv14 = nn.Conv2d(in_channels=65,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv15 = nn.Conv2d(in_channels=65,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.final_layer = nn.Conv2d(in_channels=65,out_channels=3,kernel_size=(3,3),stride=1,padding=1)\n","        \n","    def forward(self,secret_image_1,cover_image):\n","        concatenated_secrets = torch.cat([cover_image,secret_image_1],dim=1)\n","        \n","        output_1 = F.relu(self.conv1(concatenated_secrets))\n","        output_2 = F.relu(self.conv2(concatenated_secrets))\n","        output_3 = F.relu(self.conv3(concatenated_secrets))\n","        concat_1 = torch.cat([output_1,output_2,output_3],dim=1)\n","        \n","        output_4 = F.relu(self.conv4(concat_1))\n","        output_5 = F.relu(self.conv5(concat_1))\n","        output_6 = F.relu(self.conv6(concat_1))\n","        concat_2 = torch.cat([output_4,output_5,output_6],dim=1)\n","        \n","        output_7 = F.relu(self.conv7(concat_2))\n","        output_8 = F.relu(self.conv8(concat_2))\n","        output_9 = F.relu(self.conv9(concat_2))\n","        concat_3 = torch.cat([output_7,output_8,output_9],dim=1)\n","        \n","        output_10 = F.relu(self.conv10(concat_3))\n","        output_11 = F.relu(self.conv11(concat_3))\n","        output_12 = F.relu(self.conv12(concat_3))\n","        concat_4 = torch.cat([output_10,output_11,output_12],dim=1)\n","        \n","        output_13 = F.relu(self.conv13(concat_4))\n","        output_14 = F.relu(self.conv14(concat_4))\n","        output_15 = F.relu(self.conv15(concat_4))\n","        concat_5 = torch.cat([output_13,output_14,output_15],dim=1)\n","        \n","        output_converted_image = F.relu(self.final_layer(concat_5))\n","        \n","        return output_converted_image\n","class Encoder(nn.Module):\n","    def __init__(self,prep_network_1,hiding_network):\n","        super(Encoder, self).__init__()\n","        self.prep_network1 = prep_network_1\n","        self.hiding_network = hiding_network\n","    \n","    def forward(self,cover_image,secret_image_1):\n","        encoded_secret_image_1 = self.prep_network1(secret_image_1)\n","        \n","        hidden_image = self.hiding_network(encoded_secret_image_1,\n","                                           cover_image\n","                                          )\n","#         hidden_image = (0.01**0.5)*torch.randn(hidden_image.size(),device=device)\n","        return hidden_image\n","class RevealNetwork1(nn.Module):\n","    def __init__(self):\n","        super(RevealNetwork1,self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=50,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=3,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv3 = nn.Conv2d(in_channels=3,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv4 = nn.Conv2d(in_channels=65,out_channels=50,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv5 = nn.Conv2d(in_channels=65,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv6 = nn.Conv2d(in_channels=65,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv7 = nn.Conv2d(in_channels=65,out_channels=50,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv8 = nn.Conv2d(in_channels=65,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv9 = nn.Conv2d(in_channels=65,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv10 = nn.Conv2d(in_channels=65,out_channels=50,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv11 = nn.Conv2d(in_channels=65,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv12 = nn.Conv2d(in_channels=65,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv13 = nn.Conv2d(in_channels=65,out_channels=50,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv14 = nn.Conv2d(in_channels=65,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv15 = nn.Conv2d(in_channels=65,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.final_layer = nn.Conv2d(in_channels=65,out_channels=3,kernel_size=(3,3),stride=1,padding=1)    \n","    \n","    def forward(self,hidden_image):\n","        \n","        output_1 = F.relu(self.conv1(hidden_image))\n","        output_2 = F.relu(self.conv2(hidden_image))\n","        output_3 = F.relu(self.conv3(hidden_image))\n","        concat_1 = torch.cat([output_1,output_2,output_3],dim=1)\n","        \n","        output_4 = F.relu(self.conv4(concat_1))\n","        output_5 = F.relu(self.conv5(concat_1))\n","        output_6 = F.relu(self.conv6(concat_1))\n","        concat_2 = torch.cat([output_4,output_5,output_6],dim=1)\n","        \n","        output_7 = F.relu(self.conv7(concat_2))\n","        output_8 = F.relu(self.conv8(concat_2))\n","        output_9 = F.relu(self.conv9(concat_2))\n","        concat_3 = torch.cat([output_7,output_8,output_9],dim=1)\n","        \n","        output_10 = F.relu(self.conv10(concat_3))\n","        output_11 = F.relu(self.conv11(concat_3))\n","        output_12 = F.relu(self.conv12(concat_3))\n","        concat_4 = torch.cat([output_10,output_11,output_12],dim=1)\n","        \n","        output_13 = F.relu(self.conv13(concat_4))\n","        output_14 = F.relu(self.conv14(concat_4))\n","        output_15 = F.relu(self.conv15(concat_4))\n","        concat_5 = torch.cat([output_13,output_14,output_15],dim=1)\n","        \n","        output_revealed_image = F.relu(self.final_layer(concat_5))\n","        \n","        return output_revealed_image\n","class Decoder(nn.Module):\n","    def __init__(self,reveal_network_1):\n","        super().__init__()\n","        self.reveal_network_1 = reveal_network_1\n","    \n","    def forward(self,hidden_image):\n","        reveal_image_1 = self.reveal_network_1(hidden_image)\n","        return reveal_image_1\n","class SteganoModel(nn.Module):\n","    def __init__(self,encoder,decoder):\n","        super(SteganoModel,self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","    \n","    def forward(self,cover_image,secret_image_1,hidden_image,mode):\n","        if mode == 'full':\n","            for param in self.encoder.parameters():\n","                param.requires_grad = True\n","            for param in self.decoder.parameters():\n","                param.requires_grad = False\n","            hidden_image = self.encoder(cover_image,secret_image_1)\n","            reveal_image_1 = self.decoder(hidden_image)\n","            return hidden_image,reveal_image_1\n","        elif mode == 'encoder':\n","            for param in self.encoder.parameters():\n","                param.requires_grad = False\n","            for param in self.decoder.parameters():\n","                param.requires_grad = False\n","            hidden_image = self.encoder(cover_image,secret_image_1)\n","            return hidden_image\n","        elif mode == 'decoder':\n","            for param in self.encoder.parameters():\n","                param.requires_grad = False\n","            for param in self.decoder.parameters():\n","                param.requires_grad = True\n","            \n","            reveal_image1 = self.decoder(hidden_image)\n","            return reveal_image1"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5782,"status":"ok","timestamp":1684336541617,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"},"user_tz":-345},"id":"O5fnVeR_noJM","outputId":"1ede4184-7fbd-45a0-cbb1-f7115afae690"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SteganoModel(\n","  (encoder): Encoder(\n","    (prep_network1): PrepNetwork1(\n","      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    )\n","    (hiding_network): HidingNetwork(\n","      (conv1): Conv2d(68, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv2): Conv2d(68, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv3): Conv2d(68, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv7): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv8): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv9): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv10): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv11): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv12): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv13): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv14): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv15): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (final_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","  )\n","  (decoder): Decoder(\n","    (reveal_network_1): RevealNetwork1(\n","      (conv1): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv4): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv5): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv6): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv7): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv8): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv9): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv10): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv11): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv12): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv13): Conv2d(65, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv14): Conv2d(65, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv15): Conv2d(65, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (final_layer): Conv2d(65, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":5}],"source":["prep_1 = PrepNetwork1()\n","hiding_network = HidingNetwork()\n","\n","encoder = Encoder(prep_1,hiding_network)\n","\n","reveal_1 = RevealNetwork1()\n","\n","\n","decoder = Decoder(reveal_1)\n","\n","model = SteganoModel(encoder,decoder)\n","model.to(device)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":37,"status":"ok","timestamp":1684336541618,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"},"user_tz":-345},"id":"OuSHsxLUnw5R"},"outputs":[],"source":["\n","def predict(model,dataframe,mode):\n","\n","    cover_image = dataframe['cover_image']\n","    cover_image = cover_image.to(device)\n","    secret_image_1 = dataframe['secret_image']\n","    secret_image_1 = secret_image_1.to(device)\n","\n","    model.eval()\n","\n"," \n","    if mode =='decoder':\n","      \n","      reveal_image_1= model(cover_image,cover_image,cover_image,mode)\n","      \n","      # dot_graph = torchviz.make_dot(model(cover_image,cover_image,cover_image,mode))\n","      # dot_graph.render(\"decoder.dot\")\n","    elif mode =='encoder':\n","      hidden_image= model(cover_image,secret_image_1,secret_image_1,mode)\n","      # dot_graph = torchviz.make_dot(model(cover_image,secret_image_1,secret_image_1,mode))\n","      # dot_graph.render(\"encoder.dot\")\n","    elif mode == \"full\":\n","      hidden_image,reveal_image_1= model(cover_image,secret_image_1,secret_image_1,mode)\n","      # dot_graph = torchviz.make_dot(model(cover_image,secret_image_1,secret_image_1,mode))\n","      # dot_graph.render(\"full.dot\")\n","      cover_image = cover_image * 255\n","      cover_image = cover_image.to(torch.device('cpu'))\n","      cover_image = cover_image.detach().to(torch.long)\n","      secret_image_1 = secret_image_1 * 255\n","      secret_image_1 = secret_image_1.to(torch.device('cpu'))\n","      secret_image_1 = secret_image_1.detach().to(torch.long)\n","    if mode =='encoder' or mode == 'full':\n","      hidden_image[hidden_image>1] = 1\n","      hidden_image = hidden_image * 255\n","      hidden_image = hidden_image.to(torch.device('cpu'))\n","      hidden_image = hidden_image.detach().to(torch.long)\n","      h = hidden_image[0].permute(1,2,0).numpy()\n","      im = Image.fromarray(h.astype(np.uint8))\n","      im.save(\"/content/drive/MyDrive/Colab Notebooks/stego_img.png\")\n","      if mode == 'encoder': return h\n","    if mode =='decoder' or mode == 'full':\n","      reveal_image_1[reveal_image_1>1] = 1\n","      reveal_image_1 = reveal_image_1 * 255\n","      reveal_image_1 = reveal_image_1.to(torch.device('cpu'))\n","      reveal_image_1 = reveal_image_1.detach().to(torch.long)\n","      r = reveal_image_1[0].permute(1,2,0).numpy()\n","      im = Image.fromarray(r.astype(np.uint8))\n","      im.save(\"/content/drive/MyDrive/Colab Notebooks/revealed.png\")\n","      if mode == 'decoder': return r\n","    return {\n","        'cover_image_grid':cover_image[0].permute(1,2,0).numpy(),\n","        'secret_image_1_grid':secret_image_1[0].permute(1,2,0).numpy(),\n","        'hidden_image_grid':h,\n","        'reveal_image_1_grid':r,\n","    }\n","# full = predict(model,training_dataset,'full')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1684336541618,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"},"user_tz":-345},"id":"6gAVL9bdqYVs"},"outputs":[],"source":["# def plot(grids):\n","#     plt.figure(figsize=(15,8))\n","    \n","#     plt.subplot(241)\n","#     plt.title('Cover Image')\n","#     plt.imshow(grids['cover_image_grid'])\n","\n","#     plt.subplot(242)\n","#     plt.title('Secret Image')\n","#     plt.imshow(grids['secret_image_1_grid'])\n","\n","#     plt.subplot(245)\n","#     plt.title('Hidden Image')\n","#     plt.imshow(grids['hidden_image_grid'])\n","    \n","#     plt.subplot(246)\n","#     plt.title('Reveal Image')\n","#     plt.imshow(grids['reveal_image_1_grid'])\n","\n","#     plt.savefig('/content/drive/MyDrive/Colab Notebooks/Plot.png')\n","#     plt.show()\n","    "]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1684336541619,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"},"user_tz":-345},"id":"AZeTHmuVqZTr"},"outputs":[],"source":["# plot(grids)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1684336541619,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"},"user_tz":-345},"id":"U2v7gg7-42hD"},"outputs":[],"source":["def wavelet(img):  \n","    image = np.array(img)\n","\n","    n = 1\n","    w = 'db1'\n","    arr = [[],[],[]]\n","    for ch in range(3):\n","      [(cA,(cH,cV,cD))] = pywt.swt2(image[:,:,ch],wavelet=w,level=n)\n","      arr[ch] = cA / np.abs(cA).max()\n","\n","\n","    final_img = np.dstack([arr[0]*255, arr[1]*255, arr[2]*255]).astype(np.uint8)\n","    return Image.fromarray(final_img)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1684336541620,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"},"user_tz":-345},"id":"RtKllUT1HIuw"},"outputs":[],"source":["import numpy as np\n","import math, time, sys\n","from PIL import Image\n","class Arnold:\n","\n","    def __init__(self, a:int, b:int, rounds:int):\n","        # Parameters\n","        self.a = a\n","        self.b = b\n","        self.rounds = rounds\n","\n","    def mapping(self, s:np.shape):\n","        x, y = np.meshgrid(range(s[0]), range(s[0]), indexing=\"ij\")\n","        xmap = (self.a*self.b*x + x + self.a*y) % s[0]\n","        ymap = (self.b*x + y) % s[0]\n","        return xmap, ymap\n","\n","    def inverseMapping(self, s:np.shape):\n","        x, y = np.meshgrid(range(s[0]), range(s[0]), indexing=\"ij\")\n","        xmap = (x - self.a*y) % s[0]\n","        ymap = (-self.b*x + self.a*self.b*y + y) % s[0]\n","        return xmap, ymap\n","\n","    def applyTransformTo(self, image:np.ndarray):\n","        xm, ym = self.mapping(image.shape)\n","        img = image\n","        for r in range(self.rounds):\n","            img = img[xm, ym]\n","        return img\n","\n","    def applyInverseTransformTo(self, image:np.ndarray):\n","        xm, ym = self.inverseMapping(image.shape)\n","        img = image\n","        for r in range(self.rounds):\n","          img = img[xm, ym]\n","        return img"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1684336541623,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"},"user_tz":-345},"id":"dBJ5V7nf7-kP","outputId":"4dd1871a-0397-4ecb-a0bf-4b21d46606f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/DEMO/Dependencies\n"]}],"source":["%cd /content/drive/MyDrive/Colab Notebooks/DEMO/Dependencies"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21610,"status":"ok","timestamp":1684336563213,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"},"user_tz":-345},"id":"wPC2GzDIAr7d","outputId":"6c50b7ce-849e-43fc-c6b0-1c08f5dd531d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pycryptodomex\n","  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pycryptodomex\n","Successfully installed pycryptodomex-3.17\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ffmpeg-python\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n","Installing collected packages: ffmpeg-python\n","Successfully installed ffmpeg-python-0.2.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"]}],"source":["!pip install pycryptodomex\n","!pip install ffmpeg-python\n","!pip install pydub"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"AAfaxnRaqDcq","executionInfo":{"status":"ok","timestamp":1684342757788,"user_tz":-345,"elapsed":1260682,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"}},"outputId":"e2e77924-3c26-4cff-9c02-334a099b8441"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: UserWarning: You have unused kwarg parameters in Row, please remove them: {'label': 'Encode'}\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n","/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: UserWarning: You have unused kwarg parameters in Row, please remove them: {'label': 'Decode'}\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]},{"output_type":"stream","name":"stdout","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7860, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["total number of frames in cover = 149\n","Text Steganography\n","Releasing video...\n","video released\n","Extracting Cover Video Frames...\n","total number of frames in cover = 186\n","Extracting Secret Video Frames...\n","total number of frames in secret = 149\n","Hiding Metadata...\n","hiding secret video...\n","Merging Audio...\n","The Stego Video is generated in the provided path\n","Extracting Meta data...\n","extracting secret frames...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["extracting audio...\n","merging frames...\n","merging audio...\n","Keyboard interruption in main thread... closing server.\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":27}],"source":["import gradio as gr\n","from joblib import load\n","import shutil\n","from google.colab import files\n","from textinimage import Text_Steganography as ts\n","from video_in_video import Video_Encode, Video_Decode\n","import audio_in_video as av\n","import soundfile as sf\n","import datetime\n","import wave\n","# Load the saved model\n","model = load('/content/drive/MyDrive/Colab Notebooks/Steganography/Completed_model.joblib')\n","# checkpoint = torch.load('/content/drive/MyDrive/Colab Notebooks/checkpoint.pth')\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","demo = gr.Blocks()\n","\n","#Text in Image\n","\n","def ttoiEf(c_Img,s_Txt):\n","    \n","    save_path = \"/Input Files/\" # specify the directory where you want to save the image\n","    if not os.path.exists(save_path):\n","        os.makedirs(save_path)\n","    c_Img = Image.fromarray(c_Img)\n","    # while c_Img.read(1):\n","    #     pass\n","\n","    # # Reset the file pointer to the beginning of the file\n","    # c_Img.seek(0)\n","    # get the current date and time\n","    now = datetime.datetime.now()\n","\n","    # format the date and time as a string\n","    filename = 'ttoiEf'+ now.strftime(\"%Y-%m-%d_%H-%M-%S\") +'.png'\n","    file_path = os.path.join(save_path, filename)\n","    c_Img.save(file_path)\n","    ts.encode(file_path,s_Txt)\n","    filename,ext = os.path.splitext(file_path)\n","    return Image.open(f'{filename}_with_text{ext}')\n","\n","def ttoiDf(st_Img):\n","    save_path = \"/Input Files/\" # specify the directory where you want to save the image\n","    if not os.path.exists(save_path):\n","        os.makedirs(save_path)\n","    st_Img = Image.fromarray(st_Img)\n","    # while c_Img.read(1):\n","    #     pass\n","\n","    # # Reset the file pointer to the beginning of the file\n","    # c_Img.seek(0)\n","    # get the current date and time\n","    now = datetime.datetime.now()\n","\n","    # format the date and time as a string\n","    filename = 'ttoiEf'+ now.strftime(\"%Y-%m-%d_%H-%M-%S\") +'.png'\n","    file_path = os.path.join(save_path, filename)\n","    st_Img.save(file_path)\n","    return ts.decode(file_path)\n","\n","#Image in Image\n","\n","def itoiEf(c_Img,s_Img):\n","    c_Img = Image.fromarray(c_Img).resize((256,256))\n","    s_Img = Image.fromarray(s_Img).resize((256,256))\n","    \n","    a = 1\n","    b = 2\n","    rounds = 3\n","    arnold = Arnold(a, b, rounds)\n","    # Open the images\n","    s_Img_image = np.array(wavelet(s_Img))\n","    # c_Img = c_Img\n","    s_Img_image = Image.fromarray(arnold.applyTransformTo(np.array(s_Img_image)))\n","    # s_Img_image = Image.fromarray(s_Img_image)\n","    # c_Img = c_Img.resize((256,256))\n","    # c_Img = Image.fromarray(arnold.applyTransformTo(np.array(c_Img)))\n","    transform = transforms.ToTensor()\n","    transformed_c_Img_image = transform(c_Img).unsqueeze(0)\n","    transformed_s_Img_image = transform(s_Img_image).unsqueeze(0)\n","    \n","    dataframe = {\n","        'cover_image':transformed_c_Img_image,\n","        'secret_image':transformed_s_Img_image\n","    }\n","    output = predict(model,dataframe,'encoder')\n","    return Image.fromarray(output.astype(np.uint8))\n","\n","def itoiDf(st_Img):\n","    st_Img = Image.fromarray(st_Img)\n","    \n","    a = 1\n","    b = 2\n","    rounds = 3\n","    arnold = Arnold(a, b, rounds)\n","\n","    # st_Img = Image.fromarray(arnold.applyInverseTransformTo(np.array(st_Img)))\n","    transform = transforms.ToTensor()\n","    transformed_st_Img_image = transform(st_Img).unsqueeze(0)\n","    \n","    dataframe = {\n","        'cover_image':transformed_st_Img_image,\n","        'secret_image':transformed_st_Img_image\n","    }\n","    output = predict(model,dataframe,'decoder')\n","    \n","    return Image.fromarray(arnold.applyInverseTransformTo(output.astype(np.uint8)))\n","\n","#Audio in Video\n","\n","def atovEf(key,c_Vid,s_Aud):\n","    \n","    sample_rate, audio_data = s_Aud\n","    sf.write(\"output.wav\", audio_data, sample_rate)\n","\n","    stego_path = av.AIV_Encode(c_Vid,\"output.wav\",key)\n","    download_file_path = '/content/drive/MyDrive/Colab Notebooks/Steganography/Video and Audio files/stegoVid_withAudio.mp4'  # Replace with the desired download location and file name\n","\n","    shutil.move(stego_path, download_file_path)\n","    return download_file_path\n","\n","def atovDf(st_Vid,key):\n","\n","    reveal_audio_path = av.AIV_Decode(st_Vid,key)\n","    # Open the audio file\n","    with wave.open(reveal_audio_path, \"rb\") as audio_file:\n","\n","        # Get the sample rate\n","        sample_rate = audio_file.getframerate()\n","\n","        # Get the audio data\n","        audio_data = audio_file.readframes(audio_file.getnframes())\n","    return (sample_rate, audio_data)\n","\n","#Video in Video\n","\n","def vtovEf(key,c_Vid,s_Vid):\n","  \n","    output_path = Video_Encode(c_Vid, s_Vid, key,'/content/drive/MyDrive/Colab Notebooks/Steganography/Completed_model.joblib')\n","\n","    download_file_path = '/content/drive/MyDrive/Colab Notebooks/Steganography/Video and Audio files/stegoVid_withVideo.mp4'  # Replace with the desired download location and file name\n","\n","    shutil.move(output_path, download_file_path)\n","    return download_file_path\n","\n","def vtovDf(st_Vid,key):\n","    output_path = Video_Decode(st_Vid, key,'/content/drive/MyDrive/Colab Notebooks/Steganography/Completed_model.joblib')\n","    return output_path\n","\n","\n","with demo:\n","    gr.Markdown(\"Steganography Model\")\n","    with gr.Tabs():\n","        with gr.TabItem(\"Text in Image\"):\n","            with gr.Row(label= \"Encode\"):\n","                ttoiS = gr.Textbox(label=\"Enter the text to hide\")\n","                ttoiC = gr.Image(label=\"c_Img Image\")\n","                ttoiO = gr.Image(label=\"Stego Image\")\n","            ttoiE = gr.Button(\"Encode\")\n","            with gr.Row(label= \"Decode\"):\n","                ttoiSt = gr.Image(label=\"Stego Image\")\n","                ttoiR = gr.Textbox(label=\"Revealed Text\")\n","            ttoiD = gr.Button(\"Decode\")\n","        with gr.TabItem(\"Image in Image\"):\n","            with gr.Row(label= \"Encode\"):\n","                itoiC = gr.Image(label=\"c_Img Image\")\n","                itoiS = gr.Image(label=\"s_Img Image\")\n","                itoiO = gr.Image(label=\"Stego Image\")\n","            itoiE = gr.Button(\"Encode\")\n","            with gr.Row(label= \"Decode\"):\n","                itoiSt = gr.Image(label=\"Stego Image\")\n","                itoiR = gr.Image(label=\"Revealed Image\")\n","            itoiD = gr.Button(\"Decode\")\n","        with gr.TabItem(\"Audio in Video\"):\n","            with gr.Row(label= \"Encode\"):\n","                atovP = gr.Textbox(label=\"Enter password\", type=\"password\")\n","                atovC = gr.Video(label=\"c_Img Video\")\n","                atovS = gr.Audio(label=\"s_Img Audio\")\n","                atovO = gr.Textbox(label=\"Stego Path\")\n","            atovE = gr.Button(\"Encode\")\n","            with gr.Row(label= \"Decode\"):\n","                atovPd = gr.Textbox(label=\"Enter password\", type=\"password\")\n","                atovSt = gr.Textbox(label=\"Stego Path\")\n","                atovR = gr.Audio(label=\"Revealed Audio\")\n","            atovD = gr.Button(\"Decode\")\n","        with gr.TabItem(\"Video in Video\"):\n","            with gr.Row(label= \"Encode\"):\n","                vtovP = gr.Textbox(label=\"Enter password\", type=\"password\")\n","                vtovC = gr.Video(label=\"c_Img Video\")\n","                vtovS = gr.Video(label=\"s_Img Video\")\n","                vtovO = gr.Textbox(label=\"Stego Video\")\n","            vtovE = gr.Button(\"Encode\")\n","            with gr.Row(label= \"Decode\"):\n","                vtovPd = gr.Textbox(label=\"Enter password\", type=\"password\")\n","                vtovSt = gr.Textbox(label=\"Stego Path\")\n","                vtovR = gr.Video(label=\"Revealed Video\")\n","            vtovD = gr.Button(\"Decode\")\n","\n","    ttoiE.click(ttoiEf, inputs=[ttoiC,ttoiS], outputs=ttoiO)\n","    ttoiD.click(ttoiDf, inputs=ttoiSt, outputs=ttoiR)\n","    \n","    itoiE.click(itoiEf, inputs=[itoiC,itoiS], outputs=itoiO)\n","    itoiD.click(itoiDf, inputs=itoiSt, outputs=itoiR)\n","\n","    atovE.click(atovEf, inputs=[atovP,atovC,atovS], outputs=atovO)\n","    atovD.click(atovDf, inputs=[atovSt,atovSt], outputs=atovR)\n","\n","    vtovE.click(vtovEf, inputs=[vtovP,vtovC,vtovS], outputs=vtovO)\n","    vtovD.click(vtovDf, inputs=[vtovSt,vtovPd], outputs=vtovR)\n","\n","demo.launch(debug=True)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}